{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import keras \n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout \n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D \n",
    "from keras.layers.advanced_activations import LeakyReLU \n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D \n",
    "from keras.models import Sequential, Model \n",
    "from keras.optimizers import Adam,SGD \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the CIFAR10 data \n",
    "(X, y), (_, _) = keras.datasets.cifar10.load_data() \n",
    "\n",
    "#Selecting a single class images \n",
    "#The number was randomly chosen and any number \n",
    "#between 1 to 10 can be chosen \n",
    "#X = X[y.flatten() == 8] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the Input shape \n",
    "image_shape = (32, 32, 3) \n",
    "\t\t\n",
    "latent_dimensions = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(): \n",
    "\n",
    "    model = Sequential() \n",
    "\n",
    "    #Building the input layer \n",
    "    model.add(Dense(128 * 8 * 8, activation=\"relu\", \n",
    "                    input_dim=latent_dimensions)) \n",
    "    model.add(Reshape((8, 8, 128))) \n",
    "\n",
    "    model.add(UpSampling2D()) \n",
    "\n",
    "    model.add(Conv2D(128, kernel_size=3, padding=\"same\")) \n",
    "    model.add(BatchNormalization(momentum=0.78)) \n",
    "    model.add(Activation(\"relu\")) \n",
    "\n",
    "    model.add(UpSampling2D()) \n",
    "\n",
    "    model.add(Conv2D(64, kernel_size=3, padding=\"same\")) \n",
    "    model.add(BatchNormalization(momentum=0.78)) \n",
    "    model.add(Activation(\"relu\")) \n",
    "\n",
    "    model.add(Conv2D(3, kernel_size=3, padding=\"same\")) \n",
    "    model.add(Activation(\"tanh\")) \n",
    "\n",
    "\n",
    "    #Generating the output image \n",
    "    noise = Input(shape=(latent_dimensions,)) \n",
    "    image = model(noise) \n",
    "\n",
    "    return Model(noise, image) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(): \n",
    "  \n",
    "    #Building the convolutional layers \n",
    "    #to classify whether an image is real or fake \n",
    "    model = Sequential() \n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=3, strides=2, \n",
    "                     input_shape=image_shape, padding=\"same\")) \n",
    "    model.add(LeakyReLU(alpha=0.2)) \n",
    "    model.add(Dropout(0.25)) \n",
    "\n",
    "    model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\")) \n",
    "    model.add(ZeroPadding2D(padding=((0,1),(0,1)))) \n",
    "    model.add(BatchNormalization(momentum=0.82)) \n",
    "    model.add(LeakyReLU(alpha=0.25)) \n",
    "    model.add(Dropout(0.25)) \n",
    "\n",
    "    model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\")) \n",
    "    model.add(BatchNormalization(momentum=0.82)) \n",
    "    model.add(LeakyReLU(alpha=0.2)) \n",
    "    model.add(Dropout(0.25)) \n",
    "\n",
    "    model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\")) \n",
    "    model.add(BatchNormalization(momentum=0.8)) \n",
    "    model.add(LeakyReLU(alpha=0.25)) \n",
    "    model.add(Dropout(0.25)) \n",
    "\n",
    "    #Building the output layer \n",
    "    model.add(Flatten()) \n",
    "    model.add(Dense(1, activation='sigmoid')) \n",
    "\n",
    "    image = Input(shape=image_shape) \n",
    "    validity = model(image) \n",
    "\n",
    "    return Model(image, validity) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images(num): \n",
    "    r, c = 4,4\n",
    "    noise = np.random.normal(0, 1, (r * c,latent_dimensions)) \n",
    "    generated_images = generator.predict(noise) \n",
    "\n",
    "    #Scaling the generated images \n",
    "    generated_images = 0.5 * generated_images + 0.5\n",
    "\n",
    "    fig, axs = plt.subplots(r, c) \n",
    "    count = 0\n",
    "    for i in range(r): \n",
    "        for j in range(c): \n",
    "            axs[i,j].imshow(generated_images[count, :,:,]) \n",
    "            axs[i,j].axis('off') \n",
    "            count += 1\n",
    "    plt.savefig('gan2_cifar_{}.png'.format(num)) \n",
    "    plt.close() \n",
    "    generator.save('gan2_cifar_{}.h5'.format(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building and compiling the discriminator \n",
    "discriminator = build_discriminator() \n",
    "discriminator.compile(loss='binary_crossentropy', \n",
    "                      optimizer=Adam(0.0002,0.5), \n",
    "                    metrics=['accuracy']) \n",
    "  \n",
    "#Making the Discriminator untrainable \n",
    "#so that the generator can learn from fixed gradient \n",
    "discriminator.trainable = False\n",
    "  \n",
    "# Building the generator \n",
    "generator = build_generator() \n",
    "  \n",
    "#Defining the input for the generator \n",
    "#and generating the images \n",
    "z = Input(shape=(latent_dimensions,)) \n",
    "image = generator(z) \n",
    "  \n",
    "  \n",
    "#Checking the validity of the generated image \n",
    "valid = discriminator(image) \n",
    "  \n",
    "#Defining the combined model of the Generator and the Discriminator \n",
    "combined_network = Model(z, valid) \n",
    "combined_network.compile(loss='binary_crossentropy', \n",
    "                         optimizer=Adam(0.0002,0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/python3/3.6.5/lib/python3.6/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-5ca5fc1afad6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m#Sampling noise and generating a batch of new images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dimensions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mgenerated_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/apps/python3/3.6.5/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m                                             steps=steps)\n\u001b[0m\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/apps/python3/3.6.5/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/apps/python3/3.6.5/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/apps/python3/3.6.5/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/apps/python3/3.6.5/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs=15000\n",
    "batch_size=32\n",
    "display_interval=2500\n",
    "losses=[] \n",
    "\n",
    "#Normalizing the input \n",
    "X = (X / 127.5) - 1.\n",
    "\t\t\n",
    "\n",
    "#Defining the Adversarial ground truths \n",
    "valid = np.ones((batch_size, 1)) \n",
    "\n",
    "#Adding some noise \n",
    "valid += 0.05 * np.random.random(valid.shape) \n",
    "fake = np.zeros((batch_size, 1)) \n",
    "fake += 0.05 * np.random.random(fake.shape) \n",
    "\n",
    "for epoch in range(num_epochs): \n",
    "\t\t\t\n",
    "    #Training the Discriminator \n",
    "\n",
    "    #Sampling a random half of images \n",
    "    index = np.random.randint(0, X.shape[0], batch_size) \n",
    "    images = X[index] \n",
    "\n",
    "    #Sampling noise and generating a batch of new images \n",
    "    noise = np.random.normal(0, 1, (batch_size, latent_dimensions)) \n",
    "    generated_images = generator.predict(noise) \n",
    "\n",
    "\n",
    "    #Training the discriminator to detect more accurately \n",
    "    #whether a generated image is real or fake \n",
    "    discm_loss_real = discriminator.train_on_batch(images, valid) \n",
    "    discm_loss_fake = discriminator.train_on_batch(generated_images, fake) \n",
    "    discm_loss = 0.5 * np.add(discm_loss_real, discm_loss_fake) \n",
    "\n",
    "    #Training the Generator \n",
    "\n",
    "    #Training the generator to generate images \n",
    "    #which pass the authenticity test \n",
    "    genr_loss = combined_network.train_on_batch(noise, valid) \n",
    "\n",
    "    #Tracking the progress\t\t\t\t \n",
    "    if epoch % display_interval == 0: \n",
    "        display_images(epoch // display_interval) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6. (full)",
   "language": "python",
   "name": "python3-3.6-ufrc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
